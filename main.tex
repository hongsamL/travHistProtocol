\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper,margin=1.5in]{geometry}
\setlength{\parindent}{0pt}

%\title{Using BEAST to Reconstruct Pathogen Spread Incorporating Individual Travel Histories}
%GB: I would put BEAST more towards the end (as below)
\title{Reconstructing Pathogen Spread by Incorporating Individual Travel Histories in BEAST}
\author{Samuel L. Hong}
%GB: other authors: MAS, GB, PL? anyone else?

\usepackage{graphicx}
\usepackage{url}
\usepackage{mathabx}
\usepackage{sectsty}
\allsectionsfont{\normalsize\bfseries}
\usepackage{multicol}
\usepackage{changepage}
\usepackage{breakcites}

\newcommand{\ann}[1]{
\begin{adjustwidth}{0.5cm}{}
\it{#1}\\
\end{adjustwidth}}

\newcommand{\code}[1]{
{\upshape\ttfamily{#1}}}

\begin{document}

\maketitle

\begin{abstract}
\begin{adjustwidth}{0.5cm}{0.5cm}
TBD 
\end{adjustwidth}
\end{abstract}

\section*{INTRODUCTION}

%GB: Throughout this protocol, we need to keep in mind that not everyone is an expert on how to use BEAST, so let's write it for people who may have used BEAST already but don't know all the nuts and bolts and don't know how to read BEAST XML files.

Bayesian Evolutionary Analysis Sampling Trees (BEAST) \cite{beast110} is a software package that provides a general framework for phylogenetic inference and evolutionary hypothesis testing using molecular sequence data \cite{beastOG,beast17,beast110}.
As such, BEAST employs a combination of different types of models (including but not limitied to molecular clock models, coalescent models and substitution models) to infer time-calibrated phylogenetic trees from an alignment of time-stamped sequences.
Phylogenetic, phylogeographic and phylodynamic inference is performed using Bayesian inference through Markov chain Monte Carlo (MCMC) and in doing so makes use of BEAGLE, a high-performance computational library for statistical phylogenetics. %GB: insert BEAGLE citation
BEAST is widely used in the field of phylodynamics and molecular epidemiology of infectious disease to obtain insights from molecular data through an expanding array of statistical models and estimation procedures. \\
%Within this framework, it is possible to compare different evolutionary models to find which evolutionary hypothesis fits most with an epidemic processes observed. \\

A specific type of analysis that can be performed within this context is pathogen phylogeographic inference.
This type of analysis aims to answer the question of ``how did an epidemic spread through space and time?" by jointly reconstructing the evolutionary and geographical history of a pathogen population in the form of annotated time-scaled phylogenies.
%GB: I would put another sentence here mentioning the GLM paper, the importance of such a GLM, and then use the application to H3N2 in that paper to transition to the next line of text.
Bayesian phylogeographic analyses in BEAST have enjoyed wide success in uncovering the origins of viral lineages \cite{hiv} and characterizing pathogen spread to inform public health response \cite{ebola}. \\

We can use BEAST to model the spatial spread of a pathogen between discrete locations using discrete trait analysis (DTA).
This method estimates the probability of pathogen transmission between two locations using models analogous to those used for characterising nucleotide substitution probabilities \cite{dta}.
Recently, a new approach has been developed to integrate individual travel history data into DTA reconstructions in order to obtain more realistic reconstructions of pathogen spread and mitigate sampling bias \cite{travhist}. \\

We here provide four related protocols to reproduce the travel history-aware phylogeographic reconstructions performed in Lemey et. al, 2020. %GB replace 'Lemey et al.' by an actual citation?
Protocol 1 introduces the GISAID database and provides the required steps to construct a SARS-CoV-2 multiple sequence alignment from the sequences available in GISAID.
In Protocol 2, we provide instructions on how to set up a generalized linear model analysis for discrete state phylogegraphic inference using BEAUti.
Protocol 3 introduces an automated script to modify a BEAUti-generated XML file to incorporate travel history data, which can subsequently be run using BEAST.
Finally in Protocol 4, we guide the user through the process of visualizing individual geographic dispersal histories over the posterior distribution of trees, as sampled during BEAST's estimation process.


\section*{PROTOCOL 1: CREATING A SARS-CoV-2 MSA USING SEQUENCES FROM GISAID}

The first step in any phylogenetic analysis is to obtain a high-quality multiple sequence alignment (MSA).
For SARS-CoV-2 analyses, the largest repository of genomes is available through the GISAID database.
The GISAID initiative provides a platform to openly share genomic data of influenza viruses as well as SARS-CoV-2 \cite{gisaid}.
Access to the database is free (\url{https://www.gisaid.org/registration/register/}), but requires the user to register and agree to GISAID's terms of use in order to obtain access.\\

This protocol describes how to construct a SARS-CoV-2 MSA from sequences downloaded from GISAID. In this example, we will construct an alignment for the 282-taxa dataset used in Lemey et. al, 2020. %GB: replace 'Lemey et al.' by an actual citation?

\subsection*{\textbf{\textit{Necessary Resources}}}
\subsubsection*{Hardware}
\hspace{0.5cm}Standard workstation running Linux, MacOS or Windows. 

\subsubsection*{Software}
\hspace{0.5cm}A modern web browser (Google Chrome and Mozilla Firefox recommended).

\hspace{0.5cm}The latest MAFFT \cite{mafft} version (v7.453 used in this protocol) 

\hspace{0.5cm}The latest Aliview \cite{aliview} version (v1.26 used in this protocol).

\subsubsection*{Files}
\hspace{0.5cm}A list of GISAID accession numbers. 

\hspace{0.5cm}A FASTA file with the SARS-CoV-2 reference genome UTR sequences\\

\ann{Example files can be found at \code{githublink}} %GB: why is this here?

1. Search and download the desired sequences in the GISAID database \\

Log in into GISAID and click on \code{EpiCoV\textsuperscript{TM}}'s Browse tab to access a table with all available SARS-CoV-2 sequences in the database. To bulk download sequences by accession ID, click on the Fulltext{\Large $\blacktriangleup$} button, paste your comma-separated list of accessions in the search box, and download the FASTA sequences using the download button. In this example, we will save the sequences as\code{gisaid\_selection.fasta}.\\ %GB: can we provide the list of accession numbers to replicate our analysis (and mention this here)?

\ann{We can also use the \code{EpiCoV} Browse portal to download a custom selection of genomes. On the header section of the table you will see multiple search fields and drop-down menus to filter sequences according to you desired criteria.}

2. Remove white-spaces from the FASTA file %GB: need to mention any differences for bash or shell scripting?
\begin{verbatim}
sed -i.bkp "s/ /_/g" gisaid_selection.fasta 
\end{verbatim}

\ann{To avoid potential issues when parsing the FASTA headers, we replace all white-spaces in the file with underscores using \code{sed}.  We use the \code{-i} flag to find and replace the file in-place while keeping a backup of the original file.}

3. Align the sequences using MAFFT
\begin{verbatim}
cat utr.fasta >> gisaid_selection.fasta
mafft --thread -1 --nomemsave gisaid_selection.fasta > gisaid_aln.fasta
\end{verbatim}

\ann{To remove potential sequencing errors in the error-prone 5' and 3' ends of the virus, we include the reference sequences for the 5' and 3' untranslated regions (UTR) of the SARS-CoV-2 genome.
We do this so that we can later trim these regions from the final alignment.
We concatenate these sequences to the FASTA file containing our genomes of interest, and align all sequences using MAFFT.} %GB: how about mentioning here how many positions are in this alignment (i.e. after running MAFFT)? could be useful for people going through the steps; alternatively, how about providing this alignment in supplementary material?

4. Manually trim UTRs in the MSA using Aliview\\

In Aliview, visually identify the UTR sequences and manually select the corresponding sites. Remove the selected sites using the Edit menu. %GB: I think a screenshot (start of the alignment will suffice) could be useful here; if it's visually more appealing (i.e. depending on how it plays out with figure placement within the text), please also include a screenshot of the situation at the end of the alignment
Remove the now-empty reference sequences and save the trimmed MSA.\\ %GB: it may also prove useful to explicitly mention here how many sites were trimmed at both ends of the alignment

\section*{PROTOCOL 2: SETTING UP A DISCRETE TRAIT PHYLOGEOGRAPHIC RECONSTRUCTION IN BEAUTI}

Performing Bayesian phylogeographic inference while accommodating individual travel history data constitutes an extension of traditional Bayesian DTA available in BEAST. %GB: cite Lemey et al. 2009; I here use the term 'Bayesian DTA' instead of 'DTA', as the latter is not specific to BEAST in my opinion, i.e. you can do DTA using maximum likelihood
BEAUti is an interactive graphical application enabling to design the analysis you want to perform in BEAST and generates an XML file that will serve as the input file for BEAST.
This XML file contains all the required data, the models (and priors) that were selected in BEAUti, and the computational settings which will be used to run the MCMC algorithm that will collect samples of all relevant parameters (including the phylogenetic tree with annotated ancestral locations) from the posterior. \\ 

This protocol describes how to set up a DTA analysis with a generalized linear model (GLM) extension to simultaneously reconstruct spatiotemporal history and test the contribution of potential predictors of spatial spread using BEAST. %GB: cite Lemey et al. 2014
Such an approach enables parameterizing each rate of among-location movement in the phylogeographic model as a log linear function of various potential predictors.
In this example, we will use the MSA generated in Protocol 1 to set up a DTA+GLM phylogeographic reconstruction using a flight matrix and a distance matrix as covariates (but see \cite{travhist} for more detailed information). %GB: can you add a bit more information on these 2 matrices? 'flight matrix' is very general, and which distances are being used in the distance matrix?

\subsection*{\textbf{\textit{Necessary Resources}}}
\subsubsection*{Hardware}
\hspace{0.5cm}Standard workstation running Linux, MacOS, or Windows. 

\subsubsection*{Software}
\hspace{0.5cm}Latest BEAUti version (v1.10.5)

\subsubsection*{Files}
\hspace{0.5cm}Multiple sequence alignment

\hspace{0.5cm}Tab-delimited metadata file

\hspace{0.5cm}Covariate matrices in CSV format\\

\ann{Example metadata and covariate files available at\code{github}} %GB: provide an actual GitHub link + explain explicitly where these data came from (if some of them can easily be downloaded from a website, please mention this)

1. Import the MSA into BEAUti\\

Load the MSA into BEAUti by selecting Import Data from the File menu. You can also do this by dragging the FASTA file into the Partitions panel.\\

2. Specify the tip sampling dates\\

Select the Tips tab and check the ``Use tip dates" box. By default all taxa will show as having a date of zero (i.e. all sequences were sampled at the same time in the present).
To specify each sampling date, select ``Import Dates" and load the metadata file with the ``Parse calendar dates with variable precision" option. %GB: this is unclear to me; aren't the sampling times part of the sequence names/labels? If they're not, we should explain this in the text and write up what the data that you download from GISAID actually look like (let's do that). Why is there a need to load a metadata file?
This allows for taxon dates to have different degrees of resolution (e.g. year-month-day vs. year-month). We estimate the sampling dates for those sequences without day-level resolution by selecting ``Sampling uniformly from precision| in the ``Tip date sampling" menu at the bottom of the table. \\

\ann{It is also possible to specify the sampling dates without using a metadata file. This is done by parsing the FASTA headers of each sequence. To do this, click on ``Parse Dates", and specify the rules for delimiting the date from all taxon labels.} %GB: maybe a good idea to cite my protocol paper for screenshots: https://academic.oup.com/mbe/article/36/11/2620/5541799 (Figure 2a)

3. Specify the sampling location of each taxa as a discrete trait\\

Click on the Traits tab.
To associate each taxon with a sampling location, click on ``Import traits" and select the metadata file. %GB: we need to properly describe this metadata file. Is it the same one as for specifying the sampling times? Should we provide a screenshot of what it looks like?
This will create a new trait for each column on the metadata file. Delete all non-relevant traits by clicking on the ``-" button at the bottom-left of the page (keep only the ``location'' trait for this example). Select the desired trait and click on ``create partition from trait". A new partition containing the trait data will be created under the Partitions tab.\\ %GB: perhaps we can here provide a composite figure (for this entire step of the protocol)? For example, what the metadata location data look like in the file, how to delete all the non-relevant traits, and what you should see after the partition has been created.

\ann{It is also possible to add a discrete trait without using a metadata file. This is done by parsing the FASTA headers of each sequence. To do this, click on ``Add Trait" to create a new trait with a corresponding data partition. Select all taxa and click on ``Guess trait" values to parse the trait values from the taxon labels.}

4. Set up the nucleotide and trait substitution models\\

Click on the ``Sites" tab. Following Lemey et al. (2020), %GB: replace this with an actual citation command
we will specify an HKY+$\Gamma$ nucleotide substitution model, and a GLM for the location trait.
Load the covariates by clicking on ``Setup GLM'' and ``Import Predictors''. %GB: this needs more information; what does the file with covariate data look like? Which format should be specified? How many lines, and what kind of information on each line?
Check the ``Log'' and ``Std'' boxes to log-transform and standardize the GLM predictors.\\

\ann{In this context, the terms `predictor' and `covariate' are used interchangeably.
By default, each predictor name will be the same as the name of the file it originates from. %GB: give an explicit example for this particular example; this paragraph is quite general/generic at the moment
You can specify new names by double clicking on each name.
Non-pairwise covariates can also be setup as origin and destination predictors in this window.}

5. Specify a clock model\\

Following the model specifications in Lemey et al. (2020), %GB: replace this with an actual citation command
click on the ``Clocks" tab to specify a strict clock model for both the nucleotide and trait partitions.\\
\ann{BEAST analyses operate under the assumption of a molecular clock to estimate time-stamped phylogenies from the molecular sequence data and associated sampling times.
For this to hold valid, there needs to be sufficient temporal signal in the data (see the section \textbf{Critical parameters and troubleshooting}).
The presence of temporal signal in a data set can be assessed using TempEst and more formally tested using Bayesian Evaluation of Temporal Signal (BETS). %GB: cite both TempEst and BETS, and perhaps the SARS-CoV-2 BETS paper.
For more information on the different molecular clock models available in BEAST: \code{http://beast.community/clocks}} %GB: replace - throughout the manuscript - \code by \url so that the URLs can be clicked/opened.

6. Specify a demographic model\\

Click on the ``Trees" tab to specify the Tree prior. Following Lemey et al., 2020, %GB: replace this with an actual citation command
we specify an exponential growth coalescent model parameterized with a growth rate parameter.
We refer to \url{http://beast.community/tree_priors} for a more detailed explanation on a subset of the available coalescent models in BEAST. \\

\ann{By default, BEAST will initialize the analysis with a randomly generated starting tree. It is also possible to start the analysis from a user-specified time-scaled phylogeny. This is usually done to reduce the burn-in time required for the tree topologies to converge. Specify a starting tree by clicking on ``Import Data" under the ``File" menu, to load a Nexus tree into BEAUti.}

7. Set up the ancestral state reconstruction for the location trait\\

Click on the ``States" tab and select the location partition. Check the ``Reconstruct state change counts" and ``Reconstruct complete change history on tree" boxes to save complete realizations of the spatial spread process on the output trees.\\

8. Specify the priors \\

Click on the ``Priors" tab. Following Lemey et al., 2020, %GB: replace this with an actual citation command
we use default priors and only specify a Lognormal prior with \code{mu=0} and \code{sigma=10} for the effective population size, and a Laplace prior with \code{mean=0} and \code{scale=100} for the exponential growth rate parameter.\\

\ann{BEAST aims to offer sensible default priors when informative prior information is unavailable. A wide range of prior distributions is also available to customize each analysis as needed.}

9. Set up the transition kernels \\

Click on the ``Operators" tab. Identify the tip-date sampling transition kernels in the table.
These have the description ``Uniform sample from precision of age of this tip".
The parameters associated with these transition kernels tend to converge rapidly and have good mixing.
Decrease the weight of these operators to 0.25, but leave the weights of the other transition kernels at their default values, to sample these parameters less frequently so that the analysis gets to spend more time on estimating other parameters of interest.\\

\ann{Transition kernels (called ``operators'' in BEAST) are used to propose new values for each parameter being estimated during the analysis.
Different combinations of transition kernels can be used to fix certain parameters and customize the analysis as needed (e.g. estimating spatial spread on a fixed user-provided tree).}

10. Set up the MCMC options and generate the BEAST XML file\\

Click on the ``MCMC" tab. Set ``Length of chain" to 100,000,000 states and ``Log parameters every" to 50,000 states.
This will thin the MCMC results so that only 2,000 samples are collected by the end of the run.
Set your file name stem to generate the desired output file names (e.g. \texttt{282\_GISAID\_sarscov2}), and click on ``Generate BEAST File" to create the BEAST XML file for this analysis.\\

\ann{Thinning consists of storing only every $n$th sample from an MCMC analysis. This subsampling technique is done to decrease the autocorrelation in the samples collected and reduce the file size of the output. This is important since Bayesian phylogenetic analyses often require very long chains, and storing every single state would be prohibitive for file storage.}

\section*{PROTOCOL 3: PHYLOGEOGRAPHIC RECONSTRUCTION INCORPORATING TRAVEL HISTORY INFORMATION}

Phylogeographic reconstruction using DTA has been show to be sensitive to spatiotemporal sampling bias. The ancestral reconstruction of locations will depend on the availability of samples from each location. In practice, this means that over/undersampling of sequences from a given location can greatly impact the ancestral locations being reconstructed. One way to mitigate sampling bias is through the incorporation of available travel history information from infected individuals. Travel history data can be used to correct for gaps in sampling by allowing for ancestral nodes to be in a given location even when molecular sequence data are not available.\\

This protocol explains how augment a DTA analysis generated in BEAUti by incorporating individual travel history data.
In this example, we will use the XML file generated in Protocol 2 and modify it to include the available travel history data (See \cite{travhist} for more detailed information).
Importantly, BEAST requires its accompanying high-performance computational library for statistical phylogenetics -- known as BEAGLE -- %GB: add BEAGLE citation
to be installed in order to optimise computational performance on a variety of hardware resources.

\subsection*{\textbf{\textit{Necessary Resources}}}
\subsubsection*{Hardware}
\hspace{0.5cm}Standard workstation running Linux, MacOS, or Windows.

\hspace{0.5cm}CUDA-compatible Graphics Processing Unit (optional but recommended)

\subsubsection*{Software}
\hspace{0.5cm}Python v3.6+ with packages numpy and lxml

\hspace{0.5cm}BEAGLE v3+

\hspace{0.5cm}Latest BEAST jar file (v1.10.5) (provided with this protocol)

\hspace{0.5cm}\verb|add_travel_history.py| Python script (provided with this protocol)

\subsubsection*{Files}
XML file for a DTA+GLM analysis set up in BEAUti \\
Travel history metadata CSV file \\
Augmented covariate data files \\

\ann{Example files are provided in the repository {\upshape\url{github}}. %GB: replace with actual github link
The example in this protocol assumes an XML file for a DTA+GLM phylogeographic reconstruction with new travel history locations not present in the original BEAST XML file generated by BEAUti.
Covariate files augmented to include the new locations are thus required to accommodate for the increase in state space.}

1. Update the BEAST XML file to incorporate travel history data
\begin{verbatim}
python add_travel_history.py --xml 282_GISAID_sarscov2.xml
        --hist travel_metadata.csv
        --covariate augmented_flight_matrix.csv
        --covariate augmented_intra_cont_dist.csv
        --out 282_GISAID_sarscov2_travelHist.xml
\end{verbatim}

\ann{Although this example uses a DTA+GLM analysis, the\code{add\_travel\_history.py} script also works for symmetric and asymmetric DTA analyses. For such cases, run the same command without the\code{--covariate} flags. This script also requires for the travel history metadata to follow a specific format.
The metadata file must contain the following columns: ``name"  (taxon name), ``travelHistory"  (travel location), ``travelDays"  (date of travel as days before to sampling date), ``priorMean"  and ``priorSTDEV"  %GB: does STDEV need to be all capital letters? We also need to be more clear here, and perhaps provide a screenshot of the metadata file in this step.
(prior specifications for the mean and standard deviation of a normal prior on travel dates when exact data is unavailable).}

2. Run the updated XML file using BEAST
\begin{verbatim}
java -cp beast.jar dr.app.beast.BeastMain -seed 2020  
        -beagle_gpu
        -save_every 1000000
        -save_state travelHist.checkpoint
         282_GISAID_sarscov2_travelHist.xml
\end{verbatim}

\ann{Here, we execute BEAST on the command-line using the latest BEAST jar file. We specify a starting seed with the -seed flag, %GB: why? is this necessary?
and use the \code{-beagle\_cuda} flag to accelerate the likelihood computations using a GPU (only applicable if you have a powerful GPU with sufficient double precision -- or FP64 -- compute performance available).
This option is recommended when available, as using a GPU reduces runtime by accelerating likelihood computations when performing phylogeographical analyses on large datasets.
We also take advantage of the BEAST checkpointing functionality %GB: I would appreciate a citation to the online inference paper here
to save a snapshot of the MCMC run into the travelHist.checkpoint file every 1,000,000 states.
This allows us to resume the analysis from the checkpoint in case the run becomes interrupted, or more iterations of the chain are required.}

\section*{PROTOCOL 4: VISUALIZING TAXON-SPECIFIC SPATIAL TRAJECTORIES}
\subsection*{\textbf{\textit{Necessary Resources}}}
\subsubsection*{Hardware}
Standard workstation running Linux, MacOS, or Windows. 

\subsubsection*{Software}
\hspace{0.5cm}BEAGLE v3+

\hspace{0.5cm}Latest BEAST jar file (v1.10.5) (provided with this protocol)

\hspace{0.5cm}R with package MarkovJumpR

\subsubsection*{Files}
Trees output from a BEAST travel history DTA+GLM analysis \\

1. Extract all Markov jump histories for an isolate of interest
\begin{verbatim}
java -cp beast.jar dr.app.tools.TaxaMarkovJumpHistoryAnalyzer 
        -taxaToProcess "hCoV-19/Australia/NSW05/2020|EPI_ISL_412975|2020-02-28" 
        -stateAnnotation location
        -burnin 100
        -msrd 2020.1748633879781
         282_GISAID_GLM.location.history.trees EPI_ISL_412975_MJhist.csv
\end{verbatim}

\ann{The BEAST jar file packages a number of standalone tools that can be accessed using the -cp flag in Java. Here, we use the TaxaMarkovJumpHistoryAnalyzer tool to extract all Markov jump histories for isolate EPI\_ISL\_412975 , into a CSV file. This tool takes a trees file with complete state change history as an input, and outputs all spatial trajectories for some taxon/taxa. We specify the desired taxon labels through the\code{-taxaToProcess} flag, and specify the annotation name of the discrete trait which was reconstructed using \code{-stateAnnotation}.  We can also remove a burn-in number of trees using the \code{-burnin} flag, and scale the output results to reflect chronological time instead of node heights using the \code{-msrd}  flag by specifying the most recent sampling date. An example output file can be found in \code{LINK}}

2. Load spatial trajectories into R
\begin{verbatim}
library(MarkovJumpR)
spatial_paths <- loadPaths(fileName = "EPI_ISL_412975_MJhist.csv")
\end{verbatim}

3. Inspect spatial trajectories reconstructed
\begin{verbatim}
----
EXPLORE THE CSV OUTPUT IN R TO EXTRACT ALL LOCATIONS AND CUTOFF DATE
----
\end{verbatim}

4. Set up plot colors
\begin{verbatim}
locations <- c("Wuhan","Italy","SEasia","Iran","Australia")
locationColors <-c("#E3272F","#31B186","#931ECF","#C695BD","#9DC7DD")
locationMap <- data.frame(location = locations,
                position = c(1, 2, 3, 4, 5))
\end{verbatim}

5. Set up plot labels
\begin{verbatim}
dateLabels <- c("01-Dec-19", "15-Dec-19", "01-Jan-20", "15-Jan-20",
                "01-Feb-20", "15-Feb-20", "01-Mar-20" )
\end{verbatim}

6. Plot path spatial trajectories
\begin{verbatim}
plotPaths(travelHistPaths$paths, locationMap = locationMap,
        yJitterSd = 0.1, alpha = 0.1, minTime = 2019.9,
        addLocationLine = TRUE,
        xAt = decimal_date(dmy(dateLabels)),
        xLabels = dateLabels,
        mustDisplayAllLocations = TRUE)
\end{verbatim}

\section*{GUIDELINES FOR UNDERSTANDING RESULTS}

The BEAST software package offers a flexible approach for combining demographic, molecular clock, nucleotide and trait evolution models to infer time-scaled phylogenies. This is done under the Bayesian framework, using MCMC to sample trees along with their corresponding model parameters from the joint posterior. Protocols 2 and 3 are used to set up a model and collect samples using BEAST. Phylogenies drawn from the posterior are stored in a \code{.trees} file and samples from the remaining parameters are stored in a \code{.log} file. Here we present some of the standard tools used to interpret the outputs of a BEAST run.

\subsection*{Assessing convergence}

Markov Chain theory states that MCMC samplers eventually converge to a stationary distribution. In the case of Bayesian inference, this stationary distribution is the posterior. Given enough time we know that the chain will converge, but it may take considerable time for this to happen. We can visually assess the convergence of a BEAST run by inspecting the sampled parameter values across an MCMC run. To do so, we load a \code{.log} file in Tracer (\url{https://beast.community/tracer}), and visually inspect the trace plot, which shows a time series of the parameter values drawn by the sampler. A detailed guide on how to do use Tracer can be found at \url{https://beast.community/tracer_convergence.html}

\subsection*{Parameter estimates and effective sample size}

Loading a .log file in Tracer will also show the estimates and effective sample size (ESS) values for each model parameter. A characteristic of MCMC samplers is that samples collected tend to be correlated. This in turn poses a challenge, since having a large number of samples does not guarantee a considerable reduction of the uncertainty in our posterior estimates. A way to control for this is to look at the ESS values of an estimate. ESS is defined as the number of independently drawn samples equivalent to the MCMC results. Tracer will automatically calculate these values for all parameters in a log file, and flag values above 100 and 200. ESS values will increase as more and more samples are collected by the sampler. Larger ESS values will result in more precise posterior estimates but require higher computational resources. Tracer will automatically calculate the ESS for all parameters in a log file, and flag values above 100 (acceptable) and 200 (ideal).

\subsection*{Summarizing trees and phylogeographic estimates}

Individually inspecting every tree from the posterior becomes an impractical way to interpret the MCMC results. We are thus required to summarize the distribution of trees sampled as a point-estimate with associated uncertainties. The TreeAnnotator tool in BEAST allows us to create a maximum clade credibility (MCC) tree to summarize the results for this purpose. For every tree in the distribution, a posterior clade probability for each node (i.e. the support for a node) is calculated by looking at the frequency of the clustering that is defined by the node in question. The MCC tree is then defined as the tree which maximizes the product of the posterior clade probabilities. Instructions on how to use TreeAnnotator can be found at \url{beast.community/second_tutorial}. \\

In some cases, the posterior support for all nodes in a tree is such that many topologies do not end up represented in the MCC tree. For such cases, a point-estimate of a tree is unable to capture the diverse phylogeographic histories compatible with the data. Protocol 4 allows us to inspect individual spatial trajectories by summarizing across all possible phylogenetic ancestries in the posterior. Each spatial trajectory in the posterior is represented by a stepwise curve, where vertical lines represent transitions between two locations, and horizontal lines time intervals where the pathogen remains in the same location. The relative density of lines reflects the posterior uncertainty in spatiotemporal ancestry. 

\begin{multicols}{2}

\section*{COMMENTARY}
\subsection*{Background Information}

Methods for phylogeographic inference can be broadly categorized into two approaches depending on the assumptions used to model the spatial spread of a pathogen. Coalescent approaches model movement in terms of a migration matrix, and relate migration rates with a location's population size under the structured coalescent \cite{basta,mascot}. On the other hand, diffusion approaches considers sampling locations as observed traits independent from the tree generating process, and model movement across space with a continuous-time Markov chain (CTMC) \cite{dta,rw}.  While coalescent approaches are theoretically a more robust, the lack of computationally efficient implementations (especially for larger datasets) has made diffusion methods more widely adopted. Currently BEAST v1.10.5 offers only implementations for CTMC models.

Diffusion methods can be further divided into discrete and continuous depending on the spatial resolution being considered. Discrete locations are modeled using discrete trait analysis (DTA), with transition rates between locations in the form of a CTMC matrix analogous to those used for nucleotide substitution \cite{dta}. In contrast, continuous locations are modeled using Brownian diffusion based random-walk models \cite{rw}. Much of the genomic data collected has a spatial resolution coarser than latitude and longitude, which makes DTA the only practical approach to study the spread of an epidemic. 

Under the DTA formulation, movement between K discrete locations is parameterized in terms of a $K \times K$ infinitesimal rate matrix $\Lambda$, where $\Lambda_{ij}$ is the instantaneous movement rate from location $i$ to $j$. This model has been extended to allow for symmetrical and asymmetrical transition rates, and uses Bayesian Stochastic Search Variable Selection (BSSVS) to limit the number of rates to only those that adequately explain the phylogenetic diffusion process. An alternative formulation of this model parameterizes the rate matrix using a generalized linear model \cite{glm}. Here, the transition rates are defined as a linear combination of $P$ of potential explanatory predictors $(x_{ij1}, \dots, x_{ijP})$, with corresponding coefficients $(\beta_1, ..., \beta_P )$ and indicator variables $(\delta_1, ..., \delta_P )$ such that $Log(\Lambda_{ij}) = \sum_{p=1}^P \beta_p \delta_p x_{ijp}$. This model specification allows us to use BSSVS to explore the space of $2^P$ predictor combinations and obtain a posterior probability on the indicator variables to determine the support for inclusion of reach predictor in the model.

Furthermore, incorporating travel history data can be done to any of the DTA variants by augmenting augments the available dataset to include ancestral nodes associated with a known state but not with a known sequence \cite{travhist}. Ambiguous ancestral locations can also be allowed by integrating over the all possible locations with equal or user specified weights \cite{ambig}.

\section*{CRITICAL PARAMETERS AND TROUBLESHOOTING}
A critical assumption for any BEAST analysis is that of measurably evolving populations. Measurably evolving populations \cite{mep1,mep2} refer to time-stamped sequence data where a sufficient amount of molecular evolution has occurred throughout the sampling period to establish a statistical relationship between genetic divergence and time. A dataset conforming to this criteria is said to contain sufficient temporal signal. A lack of temporal signal will result in ultimately flawed analyses with unreliable divergence time estimates. Popular ways to assess temporal signal include doing a root-to-tip regression of genetic divergence and sampling times on a maximum likelihood tree \cite{tempest} and permutating tip date labels through date-randomization \cite{tipdate}. Recently, a formal way to assess temporal signal has been developed under a Bayesian framework using model comparison through Bayes factors \cite{bets}. In cases where the temporal signal is not enough, one can resort to adding more data to increase temporal coverage or using prior knowledge to inform the molecular clock rate or the time to the most recent common ancestor.

Another commonly encountered issue is that low ESS values. At the end of a BEAST run you will generally notice that some parameters have much higher ESS values than others. One way to increase the ESS values of a parameter is to decrease the weight of other parameters with enough ESS to increase the sampling frequency of the parameter of interest (e.g. Protocol 2 step 9). Other ways to obtain more samples include increasing the MCMC chain length and combining multiple independent BEAST runs.

\section*{SUGGESTIONS FOR FURTHER ANALYSIS}

TBD

\bibliographystyle{apalike}
\bibliography{protocol}

\end{multicols}

\end{document}
